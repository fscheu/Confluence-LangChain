{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = utils.config[\"LLM\"][\"OPENAI_API_KEY\"]\n",
    "os.environ[\"TAVILY_API_KEY\"] = utils.config[\"TAVILY\"][\"API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "from contextlib import ExitStack\n",
    "\n",
    "stack = ExitStack()\n",
    "memory = stack.enter_context(SqliteSaver.from_conn_string(\":memory:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed:\n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baiscf\\repos_local\\Confluence-LangChain\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# pip install tavily-python\n",
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state.get('content') or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2716c899a50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2716c899a50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2716c899a50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    should_continue,\n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2716c899a50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': 'I. Introduction\\n    A. Brief overview of Langchain and Langsmith\\n    B. Thesis statement: Exploring the differences between Langchain and Langsmith\\n\\nII. Langchain\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIII. Langsmith\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIV. Comparison between Langchain and Langsmith\\n    A. Technology stack\\n    B. Scalability\\n    C. Security\\n    D. Interoperability\\n    E. Performance\\n\\nV. Conclusion\\n    A. Recap of main differences between Langchain and Langsmith\\n    B. Implications for the future of blockchain technology\\n    C. Final thoughts and recommendations\\n\\nNotes:\\n- Ensure to provide clear definitions and explanations of both Langchain and Langsmith.\\n- Include specific examples of real-world applications for each technology.\\n- Use comparative analysis to highlight the distinctions between Langchain and Langsmith.\\n- Conclude with insights on the potential impact of these technologies on the blockchain industry.'}}\n",
      "{'research_plan': {'content': ['LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities. By understanding the differences, pros, and cons of each tool, developers can make informed decisions about which one', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses üëë to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you‚Äôre trying to figure out which tool fits your needs or you‚Äôre just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here‚Äôs how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou‚Äôre not limited to Python, though.', 'LangChain is an open-source Python library that simplifies the process of building applications with LLMs. It provides tools and abstractions to help you integrate LLMs into your projects, create robust chains and agents, and manage memory and storage.', \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\", 'LangSmith is a unified DevOps platform for developing, collaborating, testing, deploying, and monitoring LLM applications - built for every step of the appli', \"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\"]}}\n",
      "{'generate': {'draft': \"**LangChain vs LangSmith: A Comparative Analysis**\\n\\n**I. Introduction**\\n\\nIn the realm of AI language models, LangChain and LangSmith stand out as prominent tools catering to different needs. While LangChain is tailored for early-stage prototyping and small-scale applications, LangSmith is designed for large-scale, production-ready applications with advanced debugging and monitoring capabilities. This essay delves into the distinctions between LangChain and LangSmith to help developers make informed decisions.\\n\\n**II. LangChain**\\n\\nLangChain is an open-source Python library that simplifies the process of building applications with large language models (LLMs) like GPT-3. It provides tools and abstractions to integrate LLMs into projects, create robust chains and agents, and manage memory and storage efficiently. LangChain is ideal for prototyping and small-scale applications due to its ease of use and flexibility. However, it may lack the advanced debugging and testing features required for complex, large-scale projects.\\n\\n**III. LangSmith**\\n\\nOn the other hand, LangSmith serves as a unified DevOps platform tailored for large-scale, production-ready applications that demand sophisticated debugging, testing, and monitoring capabilities. It seamlessly integrates with LangChain but can also be used independently. LangSmith empowers developers to build stateful, multi-actor applications with LLMs, ensuring scalability and reliability in complex projects. Its comprehensive suite of tools makes it a preferred choice for developers working on mission-critical applications.\\n\\n**IV. Comparison between LangChain and LangSmith**\\n\\n- **Technology Stack:** LangChain primarily focuses on simplifying the integration of LLMs into applications, while LangSmith offers a comprehensive DevOps platform with advanced debugging and monitoring tools.\\n- **Scalability:** LangSmith is better suited for large-scale applications due to its robust monitoring and testing capabilities, whereas LangChain is more suitable for prototyping and small-scale projects.\\n- **Security:** Both LangChain and LangSmith prioritize security; however, LangSmith's advanced monitoring features enhance security in complex applications.\\n- **Interoperability:** LangChain and LangSmith can work together seamlessly, but LangSmith's standalone capabilities make it more versatile for diverse project requirements.\\n- **Performance:** LangSmith's advanced debugging and testing tools contribute to enhanced performance in large-scale applications compared to LangChain.\\n\\n**V. Conclusion**\\n\\nIn conclusion, understanding the differences between LangChain and LangSmith is crucial for developers to choose the right tool for their projects. While LangChain excels in simplicity and versatility for small-scale applications, LangSmith offers advanced capabilities for large-scale, production-ready projects. The future of blockchain technology will be shaped by the innovative solutions provided by tools like LangChain and LangSmith, paving the way for enhanced efficiency and reliability in AI-driven applications.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': \"**Overall Feedback:**\\nThe essay provides a clear and concise comparative analysis of LangChain and LangSmith, highlighting their key features and differences effectively. The structure of the essay is well-organized, with a logical flow from introduction to conclusion. However, there are areas where the essay could be improved to enhance its depth and clarity.\\n\\n**Content Recommendations:**\\n1. **Expand on Features:** Provide more detailed examples or use cases to illustrate the specific features and functionalities of LangChain and LangSmith. This will help readers better understand the practical implications of using each tool.\\n   \\n2. **Include User Experiences:** Incorporate real-world user experiences or testimonials to add credibility to the comparison. How have developers benefited from using LangChain or LangSmith in their projects? This can provide valuable insights for readers.\\n\\n3. **Discuss Limitations:** Address any limitations or drawbacks of both LangChain and LangSmith. Are there any specific scenarios where one tool may not be the best choice? Understanding the potential challenges can help developers make more informed decisions.\\n\\n4. **Future Developments:** Consider discussing the future roadmap or potential advancements for LangChain and LangSmith. How are these tools evolving to meet the changing demands of AI development? Providing insights into future developments can make the analysis more forward-looking.\\n\\n**Structural Recommendations:**\\n1. **Introduction and Conclusion:** While the introduction and conclusion are well-written, consider adding a brief summary of the key points discussed in the body of the essay. This can reinforce the main takeaways for the readers.\\n\\n2. **Body Paragraphs:** Each section could benefit from more detailed explanations and examples to support the comparisons made. Providing specific instances where LangChain or LangSmith excels can strengthen the analysis.\\n\\n3. **Length and Depth:** Consider expanding on each section to provide a more comprehensive analysis. Adding more depth to the comparison, such as discussing specific tools or functionalities within LangChain and LangSmith, can enhance the reader's understanding.\\n\\n4. **Visual Aids:** Incorporating visual aids like charts, diagrams, or tables to compare the features of LangChain and LangSmith can make the analysis more visually engaging and easier to comprehend.\\n\\n**Style Recommendations:**\\n1. **Consistent Terminology:** Ensure consistent use of terminology throughout the essay. This will help maintain clarity and avoid confusion for the readers.\\n\\n2. **Engaging Language:** Consider using more engaging language or examples to captivate the reader's interest. Adding anecdotes or case studies can make the analysis more relatable and engaging.\\n\\n3. **Citations:** If referencing specific studies, reports, or sources to support the analysis, remember to include citations to enhance the credibility of the information presented.\\n\\nBy incorporating these recommendations, you can further enhance the depth, clarity, and engagement of your comparative analysis of LangChain and LangSmith. Keep refining your analysis with more detailed insights and examples to provide a comprehensive understanding for your readers.\"}}\n",
      "{'research_critique': {'content': ['LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities. By understanding the differences, pros, and cons of each tool, developers can make informed decisions about which one', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses üëë to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you‚Äôre trying to figure out which tool fits your needs or you‚Äôre just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here‚Äôs how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou‚Äôre not limited to Python, though.', 'LangChain is an open-source Python library that simplifies the process of building applications with LLMs. It provides tools and abstractions to help you integrate LLMs into your projects, create robust chains and agents, and manage memory and storage.', \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\", 'LangSmith is a unified DevOps platform for developing, collaborating, testing, deploying, and monitoring LLM applications - built for every step of the appli', \"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", 'You can think of it as the ‚Äúglue code‚Äù that is needed to combine all these common functionalities around LLMs. In this article I will illustrate the most important concepts behind LangChain and explore some hands-on examples to show how you can leverage LangChain to create an application to answer questions about your own documents. Agents: Some applications require a flexible chain of calls to LLMs. LangChain provides two types of agents that help to achieve that: action agents make decisions, take actions and make observations on the results of that actions, repeating this cycle until a given task has been completed. LangChain offers many handy utilities such as document loaders, text splitters, embeddings and vector stores like Chroma.', 'The following are some of the key features of LangChain:\\nCustomizable prompts to suit your needs\\nBuilding chain link components for advanced use cases\\nCode customization for developing unique applications\\nModel integration for data augmented generation and accessing high-quality language model application like text-davinci-003\\nFlexible components to mix and match components for specific requirements\\nContext manipulation to set and guide context for improved accuracy and user experience\\nWith LangChain, you can create feature-rich applications that stand out from the crowd, thanks to its advanced customization options.\\n Following are some of the key resources that you can use when working with LangChain:\\nAI Libraries such as OpenAI and Hugging Face for AI models\\nExternal sources such as Notion, Wikipedia, and Google Drive for targeted data\\nLangChain documentation for guides on connecting and chaining components\\nOfficial Documentation\\nGitHub Repository\\nPyPI Package Repository\\nData augmentation to improve context-aware results through external data sources, indexing, and vector representations\\nLastly, engaging with the LangChain community and dedicated support slack channel can be beneficial if you encounter challenges or want to learn from others‚Äô experiences. Day(s)\\n:\\nHour(s)\\n:\\nMinute(s)\\n:\\nSecond(s)\\nBlog\\nDay(s)\\n:\\nHour(s)\\n:\\nMinute(s)\\n:\\nSecond(s)\\n So, if you‚Äôre looking to stay ahead of the curve in the world of NLP, be sure to check out LangChain and see what it can do for you!\\nRelated Posts\\nText to Code Generator: Create Code in any Language\\nAI\\nHave you ever wondered if there was an easier way to write code? Generate Accurate Code in Seconds\\nAI, Data Mentor\\nWelcome to the exhilarating world of AI Code Generators, where imagination meets execution at lightning...\\nJava Code Generator: How to Generate Java Code Quickly\\nAI, Data Mentor, Java\\nIntegrating artificial intelligence (AI) and natural language processing (NLP) has revolutionized how...\\nC++ Code Generator:', 'LangSmith by LangChain is a platform that simplifies LLM applications with debugging, testing, evaluating, and monitoring. This article covers its key components with code snippets and examples.', \"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter ü¶úüîó LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\nü¶úüîó LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: ‚Äúwhat‚Äôs happening with my application?‚Äù\", 'Despite improvements over time, such as the introduction of LangSmith, which resembles workflow automation tools like Airflow, LangChain still falls short of the maturity required for production', 'LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities']}}\n",
      "{'generate': {'draft': \"**LangChain vs LangSmith: Unveiling the Distinctions in AI Language Models**\\n\\n**I. Introduction**\\n\\nIn the realm of AI language models, LangChain and LangSmith stand out as prominent tools with distinct functionalities. While LangChain is tailored for early-stage prototyping and small-scale applications, LangSmith is designed for large-scale, production-ready projects that demand advanced debugging, testing, and monitoring capabilities. This essay delves into the nuanced disparities between LangChain and LangSmith to aid developers in making informed decisions.\\n\\n**II. LangChain**\\n\\nLangChain is an open-source Python library that streamlines the development process of applications utilizing large language models (LLMs) like GPT-3. It offers tools and abstractions to facilitate the integration of LLMs into projects, construct robust chains and agents, and manage memory and storage efficiently. LangChain empowers developers to create feature-rich applications with customizable prompts, flexible components, and context manipulation for enhanced accuracy and user experience.\\n\\n**III. LangSmith**\\n\\nIn contrast, LangSmith serves as a unified DevOps platform tailored for the comprehensive lifecycle management of LLM applications. It enables developers to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, allowing for the creation of stateful, multi-actor applications with LLMs. Its robust features cater to the needs of large-scale applications requiring meticulous debugging and monitoring capabilities.\\n\\n**IV. Comparison between LangChain and LangSmith**\\n\\nA. **Technology Stack**: LangChain primarily focuses on simplifying the development process with LLMs, while LangSmith emphasizes comprehensive application lifecycle management.\\nB. **Scalability**: LangChain is ideal for early-stage prototyping, whereas LangSmith is better suited for large-scale, production-ready applications.\\nC. **Security**: LangSmith offers advanced debugging and monitoring capabilities, enhancing the security of LLM applications.\\nD. **Interoperability**: LangChain and LangSmith can be seamlessly integrated, providing developers with a comprehensive toolkit for LLM development.\\nE. **Performance**: LangSmith's monitoring and testing features contribute to improved performance optimization in large-scale applications compared to LangChain.\\n\\n**V. Conclusion**\\n\\nIn conclusion, LangChain and LangSmith play distinct yet complementary roles in the development of applications powered by large language models. Understanding the differences between these tools is crucial for developers to choose the right platform based on their project requirements. As the landscape of AI language models continues to evolve, the synergy between LangChain and LangSmith is poised to drive innovation and efficiency in the blockchain industry, paving the way for groundbreaking advancements in AI technology.\", 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1664b5-75e0-46b7-9c2b-4ac9171f4597",
   "metadata": {},
   "source": [
    "## Essay Writer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ae270-3ec3-484a-b729-df7d2b7b0f76",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebfa79-c7fc-4aaa-b668-64e5b6cede80",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "MultiAgent = ewriter()\n",
    "app = writer_gui(MultiAgent.graph)\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
