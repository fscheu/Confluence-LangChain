{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Retrieval Augmented Generation (RAG) App\n",
    "Este archivo es una prueba siguiendo el tutorial descripto en la página: https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "```console\n",
    "py venv -m venv\n",
    ".\\\\venv\\scripts\\activate\n",
    "pip install --quiet --upgrade langchain langchain-community langchain-chroma\n",
    "pip install -qU langchain-openai\n",
    "pip install bs4\n",
    "pip install lxml\n",
    "pip install pypdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = utils.config[\"LANG\"][\"LANGCHAIN_TRACING_V2\"]\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = utils.config[\"LANG\"][\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG-PMX-Agent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat model\n",
    "\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = utils.config[\"LLM\"][\"ENDPOINT\"]\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = utils.config[\"LLM\"][\"API_KEY\"]\n",
    "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = utils.config[\"LLM\"][\"API_VERSION\"]\n",
    "# os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = utils.config[\"LLM\"][\"DEPLOYMENT\"]\n",
    "\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# llm = AzureChatOpenAI(\n",
    "#     azure_endpoint=utils.config[\"LLM\"][\"ENDPOINT\"],\n",
    "#     azure_deployment=utils.config[\"LLM\"][\"DEPLOYMENT\"],\n",
    "#     openai_api_version=utils.config[\"LLM\"][\"API_VERSION\"],\n",
    "# )\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = utils.config[\"LLM\"][\"OPENAI_API_KEY\"]\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Indexing: Load\n",
    "We need to first load the blog post contents. We can use DocumentLoaders for this, which are objects that load in data from a source and return a list of Documents. A Document is an object with some page_content (str) and metadata (dict).\n",
    "\n",
    "In this case we’ll use the WebBaseLoader, which uses urllib to load HTML from web URLs and BeautifulSoup to parse it to text. We can customize the HTML -> text parsing by passing in parameters into the BeautifulSoup parser via bs_kwargs (see BeautifulSoup docs). In this case only HTML tags with class “post-content”, “post-title”, or “post-header” are relevant, so we’ll remove all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\autoevaluacion.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\carga-plan-trabajo.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\dashboard.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\desarrollo.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\evaluacion.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\evaluaciones.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\feedback-enviado.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\feedback-recibido.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\feedback.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\index.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\mi-equipo.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\mi-perfil.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\objetivos-competencias.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\potencial.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\reportes.html\n",
      "file path: C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual\\3.02. Gestión de Performance.pdf\n",
      "2068\n",
      "\n",
      "\n",
      "\n",
      "Autoevaluación - PMX - Guía de usuarios\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "Guía de usuario PMX\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Introducción Dashboard Mi equipo\n",
      "\n",
      "Evaluaciones\n",
      "\n",
      "Introducción\n",
      "Objetivos y Competencias\n",
      "\n",
      "Carga del plan de trabajo\n",
      "Autoevaluación\n",
      "Evaluación\n",
      "\n",
      "\n",
      "Feedback\n",
      "\n",
      "Feedback Recibido\n",
      "Feedback Enviado\n",
      "\n",
      "\n",
      "Potencial\n",
      "Desarrollo\n",
      "\n",
      "\n",
      "Reportes Mi Perfil \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "En esta página\n",
      "\n",
      "\n",
      "Autoevaluación de objetivos\n",
      "Instancia de autoevaluación\n",
      "Autoevaluación de competencias\n",
      "Competencias & Comportamientos\n",
      "Comentarios sobre competencias\n",
      "Comentarios de \n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from langchain.document_loaders import BSHTMLLoader, PyPDFLoader\n",
    "\n",
    "# Ruta con un patrón de búsqueda para archivos HTML\n",
    "html_files = glob(\"C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es/*.html\")\n",
    "pdf_files = glob(\"C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/*.pdf\")\n",
    "\n",
    "# Cargar y procesar cada archivo\n",
    "documents = []\n",
    "for file_path in html_files:\n",
    "    print(f\"file path: {file_path}\")\n",
    "    loader = BSHTMLLoader(file_path, open_encoding=\"utf-8\")\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "for file_path in pdf_files:\n",
    "    print(f\"file path: {file_path}\")\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents.extend(loader.load())\n",
    "# Ahora `documents` contiene todos los documentos cargados.\n",
    "print(len(documents[0].page_content))\n",
    "\n",
    "print(documents[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "927\n",
      "{'source': 'C:/Users/baiscf/repos_local/Confluence-LangChain/PMX_Manual/tenaris/es\\\\dashboard.html', 'title': 'Dashboard - PMX - Guía de usuarios', 'start_index': 859}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(len(all_splits))\n",
    "print(len(all_splits[0].page_content))\n",
    "print(all_splits[10].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embed = AzureOpenAIEmbeddings(\n",
    "#     model=utils.config[\"EMB\"][\"MODEL\"],\n",
    "#     azure_endpoint=utils.config[\"EMB\"][\"ENDPOINT\"],\n",
    "#     api_key=utils.config[\"EMB\"][\"API_KEY\"],\n",
    "#     api_version=utils.config[\"EMB\"][\"API_VERSION\"],\n",
    "# )\n",
    "os.environ[\"OPENAI_API_KEY\"] = utils.config[\"EMB\"][\"OPENAI_API_KEY\"]\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vectorstore = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Index chunks\n",
    "_ = vectorstore.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "template = \"\"\"Sos un asistente de soporte sobre un sistema de evaluaciones de performance de empleados. Usa el contexto que se te proporciona para responder la pregunta del final.\n",
    "El material que se te proporciona es una guia de usuario del sistema y la norma de evaluacion de la empresa.\n",
    "Si no sabes la respuesta, solo di \"no se\", no trates de crear una respuesta.\n",
    "Mantene la respuesta tan conscisa como sea posible.\n",
    "Siempre contesta con \"Gracias por tu pregunta\" al final de la respuesta.\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Respuesta:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vectorstore.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = custom_rag_prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: La evaluación cliente proveedor permite a los evaluadores primarios y secundarios obtener una valoración directa de la performance de la persona, lo cual es relevante para la gestión del rendimiento. Gracias por tu pregunta.\n"
     ]
    }
   ],
   "source": [
    "#response = graph.invoke({\"question\": \"Que me podes contar sobre Dinamarca?\"})\n",
    "#response = graph.invoke({\"question\": \"Que me podes indicar sobre la autoevaluación?\"})\n",
    "#response = graph.invoke({\"question\": \"Donde puedo completar una evaluacion cliente proveedor?\"})\n",
    "response = graph.invoke({\"question\": \"Para que sirve una evaluacion cliente proveedor?\"})\n",
    "\n",
    "# print(f'Context: {response[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {response[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
